import cv2
import face_recognition
import os
import math
import numpy
from datetime import datetime

def recognizeFace():
    videoCapture = cv2.VideoCapture(0)

    def getAccuracy(faceDistance, faceMatchThreshold=0.6):
        if faceDistance > faceMatchThreshold:
            range = (1.0 - faceMatchThreshold)
            linearValue = (1.0 - faceDistance) / (range * 2.0)
            return linearValue
        else:
            range = faceMatchThreshold
            linearValue = 1.0 - (faceDistance / (range * 2.0))
            return linearValue + ((1.0 - linearValue) * math.pow((linearValue - 0.5) * 2, 0.2))

    allPaths = os.listdir(r"/Users/arshitarora/projects/face-detection-recognition/face-dataset")
    allNames = []
    allRegNumbers = []
    allEncodings = []
    for index in range(len(allPaths)):
        if allPaths[index].lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):  # Check if the file is an image
            allNames.append(allPaths[index].split(".")[0])
            allRegNumbers.append(allPaths[index].split(".")[1])
            image = face_recognition.load_image_file(r"/Users/arshitarora/projects/face-detection-recognition/face-dataset/" + allPaths[index])
            temp = face_recognition.face_encodings(image)[0]
            allEncodings.append(temp)

    while True:
        ret, frame = videoCapture.read()

        frame = cv2.resize(frame, (0, 0), fx=2, fy=1.6)

        resizedFrame = cv2.resize(frame, (0, 0), fx=0.2, fy=0.2)

        requiredFrame = cv2.cvtColor(resizedFrame, cv2.COLOR_BGR2RGB)

        faceLocation = face_recognition.face_locations(requiredFrame)
        faceEncoding = face_recognition.face_encodings(requiredFrame, faceLocation)

        for (top, right, bottom, left), encoding in zip(faceLocation, faceEncoding):
            ismatched = face_recognition.compare_faces(allEncodings, encoding)
            matchedName = "Unknown"
            faceDistance = face_recognition.face_distance(allEncodings, encoding)

            if faceDistance[0] > faceDistance[1]:
                minimumFaceDistance = faceDistance[1]
            else:
                minimumFaceDistance = faceDistance[0]

            accuracy = getAccuracy(minimumFaceDistance) * 100

            bestMatchIndex = numpy.argmin(faceDistance)

            if ismatched[bestMatchIndex] and accuracy > 80:
                matchedName = allNames[bestMatchIndex]

            cv2.rectangle(frame, (left * 5, top * 5), (right * 5, bottom * 5), (0, 255, 0), 2)
            cv2.putText(frame, f"{matchedName} ({accuracy:.2f}%)", (left * 5, (top - 10) * 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            landmarks = face_recognition.face_landmarks(requiredFrame, [((top * 5), (right * 5), (bottom * 5), (left * 5))])
            for landmark in landmarks:
                for point in landmark.values():
                    for x, y in point:
                        cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)

        cv2.imshow('Face Recognition', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    videoCapture.release()
    cv2.destroyAllWindows()

recognizeFace()
